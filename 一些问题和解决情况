
version 1.0之前雏形的建立。。。。。。。

=============================================

version 1.4
没有判断网页是否已经被爬取过，在一两层的情况下不明显，
如果层数多了没有考虑到重复的问题爬虫将会无限循环导致不能退出。。。
这是主要需要改进的一个问题

实现：
用了一个set保存了爬过的url，每次待爬取网页进入队列的时候进行匹配
不足：
并不是一种很好的方法，数据一多效率将会非常慢
待优化

=============================================

version 1.5

增加关键字搜索功能，把含有关键字的网页提取出来，
如果页面中不含有关键字，则不对网页进行操作
没有关键字的时候匹配整个页面，不知道这个地方使用汉字和正则
会不会因为编码的问题变复杂

实现：
beautifulsoup处理之后的html，keyword在html中搜索是否有匹配
不足:
html中有的时候一个关键词会被各种标签之类分开，
待用正则优化

=============================================

version 1.6

增加显示信息的详细程度，默认为1，最高是5
。。。暂时不知道爬虫的详细程度指什么 框架做好了先放着

=============================================

version 1.7	

修复了很多小问题，目前速度还处于较慢的状态
1。标题过长，导致html文件不能保存，标题中含有‘/’的时候会对导出位置造成影响（fixed）
2。对重定向情况做了一些纠正，目前重定向仍属于同一深度的同一页面（fixed）
3。中文编码造成的乱码和不能保存问题（fixed）

***********************
EMERGENCY ！！！
出现退出异常的情况，因为Qin.get(block=True, timeout=2)
block参数是后面加上的，因为设置了timeout=2，所以如果爬虫数量和很多的话有的在前几层的时候直接没有接收任务就推出了这样线程数就成了摆设，所以开始考虑增加block参数
(FIXED!!!!)
timeout参数设置时间长了一点
***********************

=============================================

version 1.8   

增加了日志功能，在开始时将任务执行语句输出到日志中
日志默认输出到Log文件中，可以用-l 参数自由选择其他目录的文件
另外Log文件中还会保存文件运行中try失败的error

=============================================

version 1.9  
实现正则爬取

之前只考虑了正则表达式中只有一个小括号()的情况，所以只输出了group(1)
所以增加了一个对正则提取内容个数的判断
			- 6.3

=============================================

version 2.0 《==== 目前进度

正则查询搜索并返回匹配内容（和关键字的搜索不同在于关键字的搜索返回整个页面，而正则搜索则是返回特定匹配正则的字段）

未完成：

*.
mac下出现编码问题不能运行
(已解决)
req.content经过解码之后decode('utf-8') / decode('gbk')可以部分解决问题
根据meta标签提取 √(已改进)
(待改进) 
仍然有网站meta声明的charset格式和实际格式不符

**.
ver1.4待优化的url去重问题， 已经严重影响到效率了， 急需解决

*.
html保存的时候根据title保存， 所以有后面和前面title相同覆盖html的情况， 增加导出到sqlite文件中，实现起来应该不难，了解下sqlite格式

*.防爬措施
1)变换UA (已实现)
2)变换XFF 
3)爬虫代理设置
4)降低频率(已实现)


*
gevent代替多线程(尝试)

*.
爬虫webui
实现webui之后可以先返回一个界面然后将鼠标选定一个界面即可将这个标签同类的标签趴下来
